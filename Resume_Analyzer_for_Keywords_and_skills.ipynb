{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Resume Analyzer for Keywords and skills using NLP**"
      ],
      "metadata": {
        "id": "WXeV-RUOWCNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "63PoJjgsiFCi",
        "outputId": "a8f2020a-9f9a-4221-c577-28800b35abeb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FNZ4-ExLigvD",
        "outputId": "3d3c9fe4-dc69-4ac3-b8b5-c86aca1f819d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7Lno96MDhs0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d486e236-64a1-42de-d0dd-e5d209dfca54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dependencies\n",
        "import re\n",
        "import PyPDF2\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import string"
      ],
      "metadata": {
        "id": "llcPhfL5jCC8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resume Analyzer for Keywords and skills For Machine Learning JOB"
      ],
      "metadata": {
        "id": "SWOKFMuHs408"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Skills TO Keywords\n",
        "keywords  = [\"python\", \"data analysis\",\"machine learning\", \"deep learning\", \"artificial intelligence\",\"nlp\", \"tensorflow\",\"keras\", \"data visualisation\", \"data science\", \"sql\", \"r\"]\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "HYYbVmdCsVjj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract text from Resume pdf\n",
        "def pdf(file_path):\n",
        "  text = \"\" # initialise text variable\n",
        "  with open(file_path,  \"rb\") as file:\n",
        "    pdf_reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    for page in pdf_reader.pages:\n",
        "      #Initialize page_text inside the loop for each page\n",
        "      page_text = \"\"\n",
        "      page_text += page.extract_text()\n",
        "      if page_text:\n",
        "        text += page_text\n",
        "  return text\n",
        "\n"
      ],
      "metadata": {
        "id": "Uz5qRX3yuY0u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenisation\n",
        "def tokenisation(text):\n",
        "  text = text.lower()\n",
        "  text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "  print(\"Filtered Tokens:\", filtered_tokens)\n",
        "\n",
        "  return filtered_tokens\n",
        "\n"
      ],
      "metadata": {
        "id": "eCLo8-G3uZDH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Match Kyewords in Resume\n",
        "def match_keywords(tokens, keywords):\n",
        "  match_keywords = [word for word in tokens if word in keywords]\n",
        "\n",
        "  return match_keywords"
      ],
      "metadata": {
        "id": "tjL0ZKikuZGj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyse Resume Score\n",
        "def analyse_resume(file_path):\n",
        "   if file_path.endswith(\".pdf\"):\n",
        "     text = pdf(file_path)\n",
        "   else:\n",
        "     return \"UNSUPPORTED FORMAT\"\n",
        "\n",
        "   tokens = tokenisation(text)\n",
        "\n",
        "   matched_keywords = match_keywords(tokens, keywords)\n",
        "   unique_matched_keywords = set(matched_keywords)\n",
        "   match_score = len(unique_matched_keywords)\n",
        "\n",
        "   print(\"Matched_keywords:\", list(unique_matched_keywords))\n",
        "   print(\"Match Score\", match_score)\n",
        "   print(f\"Skills Found:, {match_score} / {len(tokens)}\" )\n",
        "\n",
        "   score = (match_score / len(tokens)) * 100\n",
        "   print(\" Skills Found:\", score, \"%\")\n",
        "\n",
        "file_path = \"/content/ResumeDeekshaSinghSgt.pdf\"\n",
        "analyse_resume(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLfhbE2oXCDR",
        "outputId": "0cc94812-95cb-496a-c973-927f670452ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Tokens: ['deeksha', 'singh', 'deeksha25022004gmailcom', '8707681606', 'delhi', 'indiadeekshasingh2502', 'deeksha25022004', 'summary', 'enthusiastic', 'btech', 'cse', 'student', 'specializing', 'data', 'science', 'skills', 'data', 'analysis', 'machine', 'learning', 'python', 'sql', 'data', 'visualization', 'passionate', 'using', 'datadriven', 'insights', 'solve', 'realworld', 'problems', 'eager', 'grow', 'ﬁeld', 'education', 'shree', 'guru', 'gobind', 'singh', 'tricentenary', 'university', 'gurgaon', 'india', 'bachelor', 'technology', 'computer', 'science', 'engineering', '963', '2022', '2026', 'st', 'xavier', '’', 'senior', 'sec', 'school', 'kannauj', 'senior', 'secondaryclass', '12', '842', '2020', '2021', 'secondary', 'class', '10', '908', '2018', '2019', 'work', 'experience', 'codsoft', 'java', 'programming', 'intern', 'july', '2024', 'august', '2024', '•developed', 'atm', 'interface', 'using', 'java', 'implementing', 'user', 'authentication', 'transaction', 'handling', 'balance', 'inquiries', '•created', 'word', 'count', 'program', 'process', 'text', 'input', 'eﬃciently', 'count', 'word', 'occurrences', 'designed', 'number', 'game', 'java', 'enhancing', 'logical', 'thinking', 'user', 'interaction', 'projects', 'linkedin', 'job', 'data', 'scrapper', 'march', '2025', 'march', '2025', '•scraped', 'linkedin', 'job', 'listings', 'using', 'python', 'requests', 'beautifulsoup', '•automated', 'pagination', 'data', 'cleaning', 'accurate', 'results', '•classiﬁed', 'job', 'data', 'dynamically', 'stored', 'excel', 'ﬁle', 'resume', 'analyzer', 'keyword', 'skills', 'using', 'nlp', '•developed', 'nlpbased', 'system', 'extract', 'analyze', 'match', 'keywords', 'resumes', 'ml', 'roles', '•built', 'text', 'processing', 'pipeline', 'using', 'tokenization', 'stopword', 'removal', 'keyword', 'matching', '•improved', 'resume', 'analysis', 'accuracy', 'implementing', 'custom', 'keyword', 'matching', 'logic', 'customer', 'churn', 'prediction', 'developed', 'customer', 'churn', 'prediction', 'model', 'using', 'decision', 'trees', 'random', 'forest', 'svm', 'technologies', 'python', 'scikitlearn', 'pandas', 'numpy', 'matplotlib', 'seaborn', 'eda', 'skills', 'technical', 'skills', 'python', 'basics', 'java', 'sql', 'machine', 'learning', 'data', 'analytics', 'deep', 'learning', 'nlp', 'opencv', 'streamlit', 'ms', 'excel', 'ms', 'powerpoint', 'beautifulsoup', 'power', 'bi', 'libraries', 'numpy', 'pandas', 'matplotlib', 'seaborn', 'scikitlearn', 'pillow', 'tools', 'jupyter', 'google', 'colab', 'visual', 'studio', 'code', 'mysql', 'workbench', 'github', 'certificate', 'machine', 'learning', 'internshala', 'trainings', 'introduction', 'numpy', 'simplilearn', 'skillup', 'hands', 'training', 'image', 'processing', 'matlab', 'python', 'fundamentals', 'beginners', 'great', 'learning', 'academy', 'data', 'science', 'udemy', 'achievements', 'secured', '1st', 'position', 'technoquiz', 'pradarshan', '2o', 'sgt', 'university']\n",
            "Matched_keywords: ['sql', 'nlp', 'python']\n",
            "Match Score 3\n",
            "Skills Found:, 3 / 271\n",
            " Skills Found: 1.107011070110701 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oiYUZdtOZTLN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}